{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrajanNieto/cough-analyzer-Covid/blob/main/01_P2_CovidCough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Proyecto de clasificaci√≥n 'Identificacion de personas con covid'\n",
        " ----\n",
        "  \n",
        "  University : UTEC \\\\\n",
        "  Course       : Machine Learning \\\\\n",
        "  Professor    : Cristian L√≥pez Del Alamo \\\\\n",
        "  Topic        : SVM \\\\\n",
        "  Deadline      : 06-07-2025\n",
        "   \n",
        "\n",
        " ----\n",
        "\n",
        "Write the names and surnames of the members and the percentage of participation of each one in the development of the practice:\n",
        " - Integrante 1: Lopez Medina Sebastian 100%\n",
        " - Integrante 2: Nieto Espinoza Brajan Esteban 100%\n",
        " - Integrante 3: Tapia Chasquibol Mateo 100%\n",
        "\n",
        " ----\n",
        " The objective of this project is to classify patients as either having COVID or not, using only the sound of the patient‚Äôs cough. For this, your group can use libraries to obtain the best feature vector to represent the sound of the\n",
        "cough."
      ],
      "metadata": {
        "id": "WrEdLIAuVClr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1  Librerias y datos\n",
        "# ============================================\n",
        "# -------------------------------------------\n",
        "# 1.1 Clonar repositorio\n",
        "# -------------------------------------------\n",
        "!git clone https://github.com/BrajanNieto/Mlearning.git\n",
        "%cd Mlearning\n",
        "# -------------------------------------------\n",
        "# 1.2 Librer√≠as\n",
        "# -------------------------------------------\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "#  Librer√≠as extras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cvxopt\n",
        "import librosa\n",
        "import pywt\n",
        "from scipy.signal import butter, filtfilt\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "mXOi3TDd27cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d361a80d-ce58-4a87-e8df-bb2c4688dc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mlearning'...\n",
            "remote: Enumerating objects: 1551, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 1551 (delta 1), reused 0 (delta 0), pack-reused 1546 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1551/1551), 417.26 MiB | 26.01 MiB/s, done.\n",
            "Resolving deltas: 100% (265/265), done.\n",
            "Updating files: 100% (1435/1435), done.\n",
            "/content/Mlearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio Preprocessing y Extracci√≥n de Features\n",
        "\n",
        "**Puntos clave a tener en cuenta:**\n",
        "\n",
        "1. **`normalize_audio(audio)`**  \n",
        "   - Escala el pico m√°ximo de la se√±al a 0.99.  \n",
        "   - A√±ade un peque√±o epsilon (`1e-6`) para evitar divisi√≥n por cero.  \n",
        "\n",
        "2. **`remove_silence(audio, sr, top_db=50)`**  \n",
        "   - Usa `librosa.effects.split` para identificar segmentos con energ√≠a por encima de `top_db`.  \n",
        "   - Reconstruye el audio concatenando solo los intervalos activos (sin silencio).\n",
        "\n",
        "3. **`segment_audio(audio, sr, duration=1.5, hop=0.75)`**  \n",
        "   - Crea fragmentos superpuestos de longitud fija (`duration` segundos) con un salto (`hop`) entre inicios.  \n",
        "   - Calcula `frame_length = duration * sr` y `hop_length = hop * sr`.  \n",
        "   - Genera una lista de segmentos para procesamiento batch.\n",
        "\n",
        "4. **`extract_features(segment, sr)`**  \n",
        "   - Calcula **128 MFCCs** con `n_fft=512` y `hop_length=256`, y luego obtiene su valor medio.  \n",
        "   - Calcula la **tasa de cruce por cero** (zero-crossing rate) y toma su media.  \n",
        "   - Concatena ambos para un vector final de caracter√≠sticas.\n",
        "\n",
        "5. **Observaci√≥n sobre dimensiones**  \n",
        "   - Aunque el docstring menciona ‚Äúvector de 125 dimensiones‚Äù, la concatenaci√≥n de 128 MFCCs m√°s 1 valor de ZCR da **129 dimensiones**. Comprueba que downstream acepte este tama√±o."
      ],
      "metadata": {
        "id": "aoKT_uKHBXc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2  Funciones para  de Procesamiento de Audio\n",
        "# ============================================\n",
        "\n",
        "def normalize_audio(audio):\n",
        "    \"\"\"Normaliza el pico m√°ximo a 0.99.\"\"\"\n",
        "    peak = np.max(np.abs(audio)) + 1e-6\n",
        "    return audio / peak * 0.99\n",
        "\n",
        "def remove_silence(audio, sr, top_db=50):\n",
        "    \"\"\"Recorta silencios basados en un umbral de decibelios.\"\"\"\n",
        "    intervals = librosa.effects.split(audio, top_db=top_db)\n",
        "    return np.concatenate([audio[s:e] for s, e in intervals])\n",
        "\n",
        "def segment_audio(audio, sr, duration=1.5, hop=0.75):\n",
        "    \"\"\"Divide en fragmentos superpuestos de duraci√≥n fija.\"\"\"\n",
        "    fl = int(duration * sr)\n",
        "    hl = int(hop * sr)\n",
        "    return [audio[i:i+fl] for i in range(0, len(audio)-fl, hl)]\n",
        "\n",
        "def extract_features(segment, sr):\n",
        "    \"\"\"Calcula MFCCs (128) y zero‚Äêcrossing rate (1) y devuelve vector de 125 dims.\"\"\"\n",
        "    mfccs = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=128, n_fft=512, hop_length=256)\n",
        "    zcr   = librosa.feature.zero_crossing_rate(segment)\n",
        "    return np.hstack([mfccs.mean(axis=1), zcr.mean()])"
      ],
      "metadata": {
        "id": "S2xbTfhRz7U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creaci√≥n de DataFrame de Features\n",
        "\n",
        "- Recorre carpetas `Negative`, `Positive` y `Unknown`, cargando s√≥lo `.wav`.  \n",
        "- Normaliza audio y elimina silencios antes de segmentar.  \n",
        "- Segmenta en ventanas superpuestas, extrae 128 MFCCs + ZCR por segmento.  \n",
        "- Genera filas `[filename, label, mfcc‚Ä¶, zcr]`, filtra `Unknown`, no se tomara en cuenta como una categoria adicional y mapea tiquetas a 0/1.  \n"
      ],
      "metadata": {
        "id": "KBJVtPo6Bemf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3  Generaci√≥n de registros y DataFrame\n",
        "# ============================================\n",
        "base_path = 'cleaned_data'\n",
        "records = []\n",
        "for label in ['Negative', 'Positive', 'Unknown']:\n",
        "    folder = os.path.join(base_path, label)\n",
        "    for fname in os.listdir(folder):\n",
        "        if not fname.lower().endswith('.wav'):\n",
        "            continue\n",
        "        path = os.path.join(folder, fname)\n",
        "        audio, sr = librosa.load(path, sr=16000)\n",
        "        # 3.1. Preprocesamiento\n",
        "        audio = normalize_audio(audio)\n",
        "        audio = remove_silence(audio, sr)\n",
        "        # 3.2. Segmentaci√≥n\n",
        "        segments = segment_audio(audio, sr)\n",
        "        # 3.3. Extracci√≥n de features de cada segmento\n",
        "        for seg in segments:\n",
        "            feats = extract_features(seg, sr)\n",
        "            records.append([fname, label] + feats.tolist())\n",
        "\n",
        "# 3.4. Crear DataFrame con 'filename' y 'label'\n",
        "cols = ['filename', 'label'] + [f'mfcc_{i}' for i in range(128)] + ['zcr']\n",
        "df = pd.DataFrame(records, columns=cols)\n",
        "\n",
        "#3.5\n",
        "df = df[df['label'] != 'Unknown'].copy()\n",
        "mapping = {'Negative': 0, 'Positive': 1}\n",
        "df['label'] = df['label'].map(mapping)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPys7xlp17LH",
        "outputId": "d3bdc295-0ca1-4123-a2de-16d1725fec26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     filename  label      mfcc_0     mfcc_1     mfcc_2  \\\n",
            "0  602_Negative_female_24.wav      0 -372.318604  57.342354 -45.061600   \n",
            "1    866_Negative_male_29.wav      0 -357.252380  47.288013 -13.204280   \n",
            "2    866_Negative_male_29.wav      0 -364.362854  42.072475 -17.226746   \n",
            "3    866_Negative_male_29.wav      0 -385.721832  33.958363 -14.124773   \n",
            "4    866_Negative_male_29.wav      0 -389.195892  31.053137 -16.161470   \n",
            "\n",
            "      mfcc_3     mfcc_4     mfcc_5     mfcc_6     mfcc_7  ...  mfcc_119  \\\n",
            "0 -17.433853 -44.516247  -0.497882 -16.115273 -24.031391  ... -0.509453   \n",
            "1  12.651052 -27.716703   3.609981 -35.844666 -12.021462  ... -0.691036   \n",
            "2  12.977987 -28.532749   8.233962 -43.290474  -8.629445  ... -0.800812   \n",
            "3  26.623161 -12.464399  15.497139 -44.528969  -5.281589  ... -0.531144   \n",
            "4  21.019720 -12.703656  11.125703 -44.778397  -5.335186  ... -0.324802   \n",
            "\n",
            "   mfcc_120  mfcc_121  mfcc_122  mfcc_123  mfcc_124  mfcc_125  mfcc_126  \\\n",
            "0 -0.365180 -0.550728 -0.165455 -0.483451 -1.355135 -1.080396 -0.716505   \n",
            "1 -0.888819 -0.120295 -0.532270 -0.711712 -1.338131 -1.544193 -2.141667   \n",
            "2 -0.641932 -0.169620 -0.332620 -0.405354 -1.219086 -1.453555 -2.041320   \n",
            "3 -0.607188 -0.608565 -0.720199 -0.775048 -1.053042 -1.449840 -1.455495   \n",
            "4 -0.731272 -0.537169 -0.758031 -0.830815 -1.276065 -1.627204 -1.266470   \n",
            "\n",
            "   mfcc_127       zcr  \n",
            "0 -1.105229  0.248951  \n",
            "1 -1.583054  0.289062  \n",
            "2 -1.719377  0.308822  \n",
            "3 -1.695817  0.324240  \n",
            "4 -1.420950  0.326494  \n",
            "\n",
            "[5 rows x 131 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split de Datos por Archivo\n",
        "\n",
        "- Usa `GroupShuffleSplit` para dividir el 80% train y 20% test garantizando que segmentos del mismo archivo no se mezclen y que no haya overfiting.  \n",
        "- Genera `train_df` y `test_df` con √≠ndices reestablecidos.  \n",
        "- A√±ade columna `sex`: si el nombre contiene ‚Äúfemale‚Äù (no sensible a may√∫sculas) ‚Üí 1; si no ‚Üí 0.  \n",
        "- Elimina la columna `filename` al final.  \n"
      ],
      "metadata": {
        "id": "i9ZD8CwNELN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# 4  Split a nivel de archivo\n",
        "# ============================================\n",
        "\n",
        "# 4.1 Creamos un splitter que separa por grupos (filename)\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_idx, test_idx = next(\n",
        "    splitter.split(df, y=df['label'], groups=df['filename'])\n",
        ")\n",
        "\n",
        "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "test_df  = df.iloc[test_idx].reset_index(drop=True)\n",
        "# 4.2\n",
        "for subset in (train_df, test_df):\n",
        "    # 1 = female, 0 = male (u otros)\n",
        "    subset['sex'] = np.where(\n",
        "        subset['filename'].str.contains('female', case=False),\n",
        "        1, 0\n",
        "    )\n",
        "    subset.drop(columns=['filename'], inplace=True)\n"
      ],
      "metadata": {
        "id": "JJRvHnUBC0XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparaci√≥n de Conjuntos de Entrenamiento y Prueba\n",
        "\n",
        "- Separa **features** (`X`) y **labels** (`y`) en `train_df` y `test_df`.  \n",
        "- Elimina la columna `label` de `X_train` y `X_test`.  \n",
        "- Muestra dimensiones de cada set y conteo de clases (`value_counts`).  \n"
      ],
      "metadata": {
        "id": "On_Y4JmbE7Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5  Preparar X e y para entrenamiento y prueba\n",
        "# ============================================\n",
        "X_train = train_df.drop(columns='label')\n",
        "y_train = train_df['label']\n",
        "\n",
        "X_test  = test_df.drop(columns='label')\n",
        "y_test  = test_df['label']\n",
        "\n",
        "# 7. Vista previa (opcional)\n",
        "print(\"Train set:\", X_train.shape, y_train.value_counts().to_dict())\n",
        "print(\"Test  set:\", X_test.shape,  y_test.value_counts().to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-BYeichHJ2q",
        "outputId": "5b1dbb7e-8451-4743-e3d3-aea371590bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (3969, 130) {0: 3673, 1: 296}\n",
            "Test  set: (929, 130) {0: 850, 1: 79}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuraci√≥n de Modelos y B√∫squeda de Hiperpar√°metros\n",
        "\n",
        "- **Pipelines**  \n",
        "  - Escalado con `StandardScaler` para regresi√≥n log√≠stica, SVM y KNN; √°rbol de decisi√≥n sin escalado.  \n",
        "  - Todos los clasificadores usan `class_weight='balanced'` salvo KNN.\n",
        "\n",
        "- **Modelos incluidos**  \n",
        "  - **LogReg**: regresi√≥n log√≠stica (solver lbfgs, iteraciones 1000)  \n",
        "  - **SVM**: m√°quina de vectores de soporte con n√∫cleo RBF (probabilidad desactivada)  \n",
        "  - **DT**: √°rbol de decisi√≥n  \n",
        "  - **KNN**: k vecinos m√°s cercanos\n",
        "\n",
        "- **Grillas de hiperpar√°metros**  \n",
        "  - **LogReg**: b√∫squeda de constantes de regularizaci√≥n `C` (valores de 0.01 a 100)  \n",
        "  - **SVM**: `C` (0.1‚Äì10) y `gamma` (‚Äòscale‚Äô o 0.1)  \n",
        "  - **DT**: profundidades de 2 a 100 (o ilimitada) y muestras m√≠nimas por hoja 1‚Äì10  \n",
        "  - **KNN**: n√∫mero de vecinos entre 2 y 30\n"
      ],
      "metadata": {
        "id": "zSVmwq2tE9o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 6. Definici√≥n de pipelines y grids\n",
        "# -------------------------------------------\n",
        "base_pipes = {\n",
        "    'LogReg': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=1_000, solver='lbfgs',\n",
        "                                   class_weight='balanced', random_state=42))\n",
        "    ]),\n",
        "    'SVM': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', SVC(kernel='rbf', class_weight='balanced', probability=False,\n",
        "                    random_state=42))\n",
        "    ]),\n",
        "    'DT': Pipeline([\n",
        "        ('clf', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
        "    ]),\n",
        "    'KNN': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', KNeighborsClassifier())   # KNN no usa class_weight\n",
        "    ])\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'LogReg': {'clf__C': [0.01, 0.1, 1, 10, 100, 0.5, 0.6, 0.7]},\n",
        "    'SVM'   : {'clf__C': [0.1, 1, 1.5, 10],\n",
        "               'clf__gamma': ['scale', 0.1]},\n",
        "    'DT'    : {'clf__max_depth': [None, 5, 10],\n",
        "               'clf__min_samples_leaf': [2, 3, 5]},\n",
        "    'KNN'   : {'clf__n_neighbors': [2, 3, 4, 10, 20, 30]}\n",
        "}"
      ],
      "metadata": {
        "id": "70Qzbitxl2Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n con Grid Search y Validaci√≥n Cruzada\n",
        "\n",
        "- Itera sobre cada pipeline en `base_pipes`.  \n",
        "- Usa `StratifiedKFold(n_splits=10, shuffle=True)` como CV interno.  \n",
        "- Configura `GridSearchCV` con:\n",
        "  - `scoring='f1_weighted'`  \n",
        "  - `n_jobs=-1` para paralelizar  \n",
        "  - `refit=True` para conservar el mejor modelo.  \n",
        "- Ajusta (`fit`) en `X_train`, `y_train` y almacena el mejor estimador en `best_estimators[name]`.  \n",
        "- Imprime el mejor `f1` obtenido y los par√°metros √≥ptimos (`best_params_`).  \n"
      ],
      "metadata": {
        "id": "MLUDWZFyFN-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# -------------------------------------------\n",
        "# 7. Grid Search + Bootstrap\n",
        "# -------------------------------------------\n",
        "B = 10  # n√∫mero de remuestreos bootstrap\n",
        "best_estimators = {}\n",
        "\n",
        "for name, pipe in base_pipes.items():\n",
        "    print(f\"\\nModelo: {name}\")\n",
        "    print(\"-\" * 80)\n",
        "    best_score = -np.inf\n",
        "    best_params = None\n",
        "\n",
        "    # Recorremos cada combinaci√≥n de hiperpar√°metros\n",
        "    for params in ParameterGrid(param_grids[name]):\n",
        "        pipe.set_params(**params)\n",
        "        boot_metrics = []\n",
        "\n",
        "        # Generamos B muestras bootstrap\n",
        "        for b in range(B):\n",
        "            # Bootstrap sobre X_train, y_train\n",
        "            X_bs, y_bs = resample(\n",
        "                X_train, y_train,\n",
        "                replace=True,\n",
        "                random_state=42 + b\n",
        "            )\n",
        "            # √çndices OOB (no seleccionados en bootstrap)\n",
        "            oob_mask = ~X_train.index.isin(X_bs.index)\n",
        "            X_oob, y_oob = X_train[oob_mask], y_train[oob_mask]\n",
        "            if y_oob.shape[0] == 0:\n",
        "                continue\n",
        "\n",
        "            # Entrenamos y predecimos\n",
        "            pipe.fit(X_bs, y_bs)\n",
        "            y_pred = pipe.predict(X_oob)\n",
        "\n",
        "            # Calculamos m√©tricas weighted\n",
        "            prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "                y_oob, y_pred,\n",
        "                average='weighted',\n",
        "                zero_division=0\n",
        "            )\n",
        "            boot_metrics.append((prec, rec, f1))\n",
        "\n",
        "        # Si no hubo OOB v√°lido, saltamos\n",
        "        if not boot_metrics:\n",
        "            continue\n",
        "\n",
        "        # Media y desviaci√≥n de cada m√©trica\n",
        "        arr = np.array(boot_metrics)\n",
        "        mean_prec, mean_rec, mean_f1 = arr.mean(axis=0)\n",
        "        std_prec, std_rec, std_f1 = arr.std(axis=0)\n",
        "\n",
        "        # Imprimimos resultados para esta combinaci√≥n\n",
        "        print(f\"params = {params}\")\n",
        "        print(\n",
        "            f\"  f1   = {mean_f1:.3f} ¬±{std_f1:.3f}  |  \"\n",
        "            f\"prec = {mean_prec:.3f} ¬±{std_prec:.3f}  |  \"\n",
        "            f\"rec  = {mean_rec:.3f} ¬±{std_rec:.3f}\"\n",
        "        )\n",
        "\n",
        "        # Actualizamos mejor modelo seg√∫n f1 medio\n",
        "        if mean_f1 > best_score:\n",
        "            best_score = mean_f1\n",
        "            best_params = params\n",
        "            # Clonamos el pipe con esos par√°metros\n",
        "            from sklearn.base import clone\n",
        "            best_estimators[name] = clone(pipe)\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(\n",
        "        f\"‚úì Mejor f1 medio = {best_score:.3f}  con params = {best_params}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "xLmFz_uGlv8i",
        "outputId": "d46a0868-2513-4c9b-8e7b-dbd2122add0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo: LogReg\n",
            "--------------------------------------------------------------------------------\n",
            "params = {'clf__C': 0.01}\n",
            "  f1   = 0.839 ¬±0.009  |  prec = 0.913 ¬±0.006  |  rec  = 0.797 ¬±0.013\n",
            "params = {'clf__C': 0.1}\n",
            "  f1   = 0.839 ¬±0.008  |  prec = 0.911 ¬±0.007  |  rec  = 0.798 ¬±0.012\n",
            "params = {'clf__C': 1}\n",
            "  f1   = 0.839 ¬±0.007  |  prec = 0.909 ¬±0.008  |  rec  = 0.797 ¬±0.010\n",
            "params = {'clf__C': 10}\n",
            "  f1   = 0.839 ¬±0.007  |  prec = 0.909 ¬±0.008  |  rec  = 0.798 ¬±0.010\n",
            "params = {'clf__C': 100}\n",
            "  f1   = 0.839 ¬±0.007  |  prec = 0.909 ¬±0.008  |  rec  = 0.798 ¬±0.010\n",
            "params = {'clf__C': 0.5}\n",
            "  f1   = 0.839 ¬±0.008  |  prec = 0.910 ¬±0.008  |  rec  = 0.797 ¬±0.011\n",
            "params = {'clf__C': 0.6}\n",
            "  f1   = 0.839 ¬±0.007  |  prec = 0.909 ¬±0.008  |  rec  = 0.798 ¬±0.011\n",
            "params = {'clf__C': 0.7}\n",
            "  f1   = 0.839 ¬±0.007  |  prec = 0.909 ¬±0.008  |  rec  = 0.798 ¬±0.010\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Mejor f1 medio = 0.839  con params = {'clf__C': 0.01}\n",
            "\n",
            "Modelo: SVM\n",
            "--------------------------------------------------------------------------------\n",
            "params = {'clf__C': 0.1, 'clf__gamma': 'scale'}\n",
            "  f1   = 0.902 ¬±0.009  |  prec = 0.925 ¬±0.007  |  rec  = 0.888 ¬±0.015\n",
            "params = {'clf__C': 0.1, 'clf__gamma': 0.1}\n",
            "  f1   = 0.889 ¬±0.006  |  prec = 0.855 ¬±0.007  |  rec  = 0.925 ¬±0.004\n",
            "params = {'clf__C': 1, 'clf__gamma': 'scale'}\n",
            "  f1   = 0.964 ¬±0.008  |  prec = 0.966 ¬±0.007  |  rec  = 0.967 ¬±0.007\n",
            "params = {'clf__C': 1, 'clf__gamma': 0.1}\n",
            "  f1   = 0.889 ¬±0.006  |  prec = 0.855 ¬±0.007  |  rec  = 0.925 ¬±0.004\n",
            "params = {'clf__C': 1.5, 'clf__gamma': 'scale'}\n",
            "  f1   = 0.963 ¬±0.008  |  prec = 0.966 ¬±0.007  |  rec  = 0.967 ¬±0.007\n",
            "params = {'clf__C': 1.5, 'clf__gamma': 0.1}\n",
            "  f1   = 0.889 ¬±0.006  |  prec = 0.855 ¬±0.007  |  rec  = 0.925 ¬±0.004\n",
            "params = {'clf__C': 10, 'clf__gamma': 'scale'}\n",
            "  f1   = 0.962 ¬±0.008  |  prec = 0.966 ¬±0.007  |  rec  = 0.966 ¬±0.007\n",
            "params = {'clf__C': 10, 'clf__gamma': 0.1}\n",
            "  f1   = 0.889 ¬±0.006  |  prec = 0.855 ¬±0.007  |  rec  = 0.925 ¬±0.004\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Mejor f1 medio = 0.964  con params = {'clf__C': 1, 'clf__gamma': 'scale'}\n",
            "\n",
            "Modelo: DT\n",
            "--------------------------------------------------------------------------------\n",
            "params = {'clf__max_depth': None, 'clf__min_samples_leaf': 2}\n",
            "  f1   = 0.883 ¬±0.008  |  prec = 0.886 ¬±0.008  |  rec  = 0.881 ¬±0.010\n",
            "params = {'clf__max_depth': None, 'clf__min_samples_leaf': 3}\n",
            "  f1   = 0.881 ¬±0.006  |  prec = 0.887 ¬±0.007  |  rec  = 0.875 ¬±0.007\n",
            "params = {'clf__max_depth': None, 'clf__min_samples_leaf': 5}\n",
            "  f1   = 0.873 ¬±0.006  |  prec = 0.889 ¬±0.007  |  rec  = 0.860 ¬±0.007\n",
            "params = {'clf__max_depth': 5, 'clf__min_samples_leaf': 2}\n",
            "  f1   = 0.792 ¬±0.018  |  prec = 0.898 ¬±0.007  |  rec  = 0.732 ¬±0.028\n",
            "params = {'clf__max_depth': 5, 'clf__min_samples_leaf': 3}\n",
            "  f1   = 0.791 ¬±0.019  |  prec = 0.898 ¬±0.007  |  rec  = 0.731 ¬±0.028\n",
            "params = {'clf__max_depth': 5, 'clf__min_samples_leaf': 5}\n",
            "  f1   = 0.791 ¬±0.019  |  prec = 0.898 ¬±0.007  |  rec  = 0.730 ¬±0.028\n",
            "params = {'clf__max_depth': 10, 'clf__min_samples_leaf': 2}\n",
            "  f1   = 0.862 ¬±0.013  |  prec = 0.894 ¬±0.008  |  rec  = 0.838 ¬±0.021\n",
            "params = {'clf__max_depth': 10, 'clf__min_samples_leaf': 3}\n",
            "  f1   = 0.859 ¬±0.012  |  prec = 0.893 ¬±0.007  |  rec  = 0.834 ¬±0.019\n",
            "params = {'clf__max_depth': 10, 'clf__min_samples_leaf': 5}\n",
            "  f1   = 0.853 ¬±0.011  |  prec = 0.893 ¬±0.008  |  rec  = 0.825 ¬±0.018\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Mejor f1 medio = 0.883  con params = {'clf__max_depth': None, 'clf__min_samples_leaf': 2}\n",
            "\n",
            "Modelo: KNN\n",
            "--------------------------------------------------------------------------------\n",
            "params = {'clf__n_neighbors': 2}\n",
            "  f1   = 0.965 ¬±0.006  |  prec = 0.968 ¬±0.005  |  rec  = 0.968 ¬±0.005\n",
            "params = {'clf__n_neighbors': 3}\n",
            "  f1   = 0.963 ¬±0.005  |  prec = 0.963 ¬±0.005  |  rec  = 0.965 ¬±0.004\n",
            "params = {'clf__n_neighbors': 4}\n",
            "  f1   = 0.950 ¬±0.008  |  prec = 0.955 ¬±0.007  |  rec  = 0.957 ¬±0.006\n",
            "params = {'clf__n_neighbors': 10}\n",
            "  f1   = 0.924 ¬±0.009  |  prec = 0.937 ¬±0.007  |  rec  = 0.940 ¬±0.006\n",
            "params = {'clf__n_neighbors': 20}\n",
            "  f1   = 0.902 ¬±0.008  |  prec = 0.928 ¬±0.008  |  rec  = 0.930 ¬±0.005\n",
            "params = {'clf__n_neighbors': 30}\n",
            "  f1   = 0.895 ¬±0.007  |  prec = 0.919 ¬±0.027  |  rec  = 0.927 ¬±0.005\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Mejor f1 medio = 0.965  con params = {'clf__n_neighbors': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n en Conjunto de Prueba\n",
        "\n",
        "- Para cada modelo √≥ptimo en `best_estimators`:  \n",
        "  - Predice etiquetas sobre `X_test`.  \n",
        "  - Calcula **precision**, **recall** y **f1 ponderado**.  \n",
        "- Almacena los resultados en una lista de diccionarios con claves `model`, `precision`, `recall`, `f1`.  \n",
        "- Convierte la lista en un DataFrame, lo indexa por `model` y redondea a 3 decimales.  \n",
        "- Imprime la tabla resultante en formato Markdown (`to_markdown()`).  \n"
      ],
      "metadata": {
        "id": "Igrk54idFgYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 8. Evaluaci√≥n en test con los mejores estimadores\n",
        "# -------------------------------------------\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "results_test = []\n",
        "\n",
        "for name, est in best_estimators.items():\n",
        "    # 0) Ajustamos el pipeline completo sobre X_train, y_train\n",
        "    est.fit(X_train, y_train)\n",
        "\n",
        "    # 1) Predecimos sobre X_test\n",
        "    y_pred = est.predict(X_test)\n",
        "\n",
        "    # 2) Calculamos precision, recall y f1 ponderado\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    recall    = recall_score(   y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1        = f1_score(       y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    results_test.append({\n",
        "        'model':     name,\n",
        "        'precision': precision,\n",
        "        'recall':    recall,\n",
        "        'f1':        f1,\n",
        "    })\n",
        "\n",
        "df_test = pd.DataFrame(results_test).set_index('model').round(3)\n",
        "print(df_test.to_markdown())\n"
      ],
      "metadata": {
        "id": "U8QE7yInnzLb",
        "outputId": "493fc82c-7c19-487b-ed56-96fc7bc3fb32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| model   |   precision |   recall |    f1 |\n",
            "|:--------|------------:|---------:|------:|\n",
            "| LogReg  |       0.873 |    0.76  | 0.805 |\n",
            "| SVM     |       0.916 |    0.926 | 0.904 |\n",
            "| DT      |       0.866 |    0.87  | 0.868 |\n",
            "| KNN     |       0.909 |    0.92  | 0.89  |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svmb = best_estimators['SVM']\n",
        "y_pred = svmb.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, index=svmb.classes_, columns=svmb.classes_)\n",
        "print(\"Matriz de confusi√≥n (SVM):\")\n",
        "print(cm_df)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy total (SVM): {acc:.3f}\")"
      ],
      "metadata": {
        "id": "V9jH9M7mE7ed",
        "outputId": "577e55be-569d-466f-fd00-4656927512ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusi√≥n (SVM):\n",
            "     0   1\n",
            "0  846   4\n",
            "1   65  14\n",
            "\n",
            "Accuracy total (SVM): 0.926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Serializar y Guardar el Modelo SVM\n",
        "\n",
        "- Se extrae el mejor estimador SVM: `svm_model = best_estimators['SVM']`.  \n",
        "- Se usa `joblib.dump` para guardar el objeto en disco:  \n",
        "  ```python\n",
        "  joblib.dump(svm_model, 'svm_model.pkl')"
      ],
      "metadata": {
        "id": "wKwOpvS4FtE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "svm_model = best_estimators['SVM']\n",
        "joblib.dump(svm_model, 'svm_model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkRyzA_KJJot",
        "outputId": "6a208c77-82ae-411d-b3be-8e1842fb78b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get update -qq\n",
        "#!apt-get install -y libportaudio2 portaudio19-dev\n",
        "#!pip install --upgrade --force-reinstall sounddevice"
      ],
      "metadata": {
        "id": "NUrk17MXLXQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**USANDO EL ALGORITMO ENTRENADO:**  \n",
        "Est a secci[on ofrece una interfaz de l√≠nea de comandos para predecir si un clip de tos es ‚ÄúPositive‚Äù o ‚ÄúNegative‚Äù para covid (etiqueta binaria) usando un modelo SVM previamente entrenado con caracter√≠sticas MFCC + ZCR.  \n",
        "\n",
        "**Flujo principal:**  \n",
        "1. **Parseo de argumentos**  \n",
        "   - `--file`: ruta del audio (WAV, MP3, etc.)  \n",
        "   - `--sex`: 0 (male/otro) o 1 (female)  \n",
        "   - `--model`: archivo `.pkl` del modelo SVM  \n",
        "\n",
        "2. **Carga del modelo**  \n",
        "   - Valida existencia y carga con `joblib.load`.  \n",
        "\n",
        "3. **Obtenci√≥n del archivo de audio**  \n",
        "   - Si no se pasa `--file`, permite subir en Colab o pide ruta local.  \n",
        "\n",
        "7. **Salida de resultados**  \n",
        "   - Muestra nombre de archivo, recuentos por segmento y porcentaje de confianza.  \n",
        "   - Imprime mensaje final personalizado:  \n",
        "     - Si etiqueta = 0 ‚Üí ‚ÄúNO TIENES COVID!‚Äù  \n",
        "     - Si etiqueta ‚â† 0 ‚Üí ‚ÄúSI TIENES COVID U.U‚Äù  \n"
      ],
      "metadata": {
        "id": "9XzY-oPLGBpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Inferencia de polaridad ('Positive'/'Negative') de un clip de voz\n",
        "usando un modelo SVM entrenado con MFCC + ZCR.\n",
        "\n",
        "‚úÖ VERSI√ìN SIMPLIFICADA - SOLO SUBIDA DE ARCHIVOS\n",
        "-------------------------------------------------\n",
        "1. Subir archivo de audio WAV\n",
        "2. Extrae features con librosa\n",
        "3. Ejecuta predicci√≥n con modelo SVM\n",
        "\n",
        "Autor original: <tu nombre>\n",
        "√öltima revisi√≥n: 29‚Äëjun‚Äë2025\n",
        "\"\"\"\n",
        "\n",
        "# ============================ Imports =======================================\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import load\n",
        "\n",
        "# ---------- Dependencias opcionales seg√∫n entorno ----------\n",
        "COLAB = False\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    from google.colab import files  # type: ignore\n",
        "    COLAB = True\n",
        "except ImportError:\n",
        "    # Ejecuci√≥n local\n",
        "    pass\n",
        "\n",
        "# ========================== 1. Pre‚Äëprocesamiento ============================\n",
        "\n",
        "def normalize_audio(audio: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Normaliza a ¬±0.99 para evitar clipping.\"\"\"\n",
        "    peak = np.max(np.abs(audio)) + 1e-6\n",
        "    return audio / peak * 0.99\n",
        "\n",
        "\n",
        "def remove_silence(audio: np.ndarray, sr: int, top_db: int = 60) -> np.ndarray:\n",
        "    \"\"\"Elimina silencios usando librosa.effects.split.\"\"\"\n",
        "    intervals = librosa.effects.split(audio, top_db=top_db)\n",
        "    return (\n",
        "        np.concatenate([audio[s:e] for s, e in intervals])\n",
        "        if intervals.size\n",
        "        else audio\n",
        "    )\n",
        "\n",
        "\n",
        "def segment_audio(audio: np.ndarray, sr: int, duration: float = 1.5, hop: float = 0.75) -> list[np.ndarray]:\n",
        "    \"\"\"Ventanas deslizantes de `duration` s cada `hop` s.\"\"\"\n",
        "    fl, hl = int(duration * sr), int(hop * sr)\n",
        "    return [audio[i : i + fl] for i in range(0, len(audio) - fl + 1, hl)]\n",
        "\n",
        "\n",
        "def extract_features(segment: np.ndarray, sr: int) -> np.ndarray:\n",
        "    \"\"\"MFCC (128) + ZCR (1) ‚Üí vector 129‚Äëd.\"\"\"\n",
        "    mfccs = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=128, n_fft=512, hop_length=256)\n",
        "    zcr = librosa.feature.zero_crossing_rate(segment)\n",
        "    return np.hstack([mfccs.mean(axis=1), zcr.mean()])\n",
        "\n",
        "# ============================== 2. Modelo ====================================\n",
        "\n",
        "def load_model(path: str):\n",
        "    \"\"\"Carga el modelo serializado con joblib/pickle.\"\"\"\n",
        "    if not os.path.isfile(path):\n",
        "        sys.exit(f\"‚ö†Ô∏è  No existe el modelo: {path}\")\n",
        "    return load(path)\n",
        "\n",
        "# ========================== 3. Audio helpers =================================\n",
        "\n",
        "def upload_audio_colab() -> str:\n",
        "    \"\"\"Subir archivo de audio en Colab.\"\"\"\n",
        "    print(\"üìÅ Por favor, selecciona un archivo de audio WAV...\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        sys.exit(\"‚ö†Ô∏è  No se subi√≥ ning√∫n archivo.\")\n",
        "\n",
        "    fname = next(iter(uploaded))\n",
        "    if not fname.lower().endswith((\".wav\", \".mp3\", \".m4a\", \".flac\")):\n",
        "        print(\"‚ö†Ô∏è Formato no √≥ptimo. Se recomienda WAV, pero se intentar√° procesar.\")\n",
        "\n",
        "    return fname\n",
        "\n",
        "def get_audio_file_local() -> str:\n",
        "    \"\"\"Obtener archivo de audio en ejecuci√≥n local.\"\"\"\n",
        "    while True:\n",
        "        file_path = input(\"üìÅ Ruta del archivo de audio: \").strip()\n",
        "        if os.path.isfile(file_path):\n",
        "            return file_path\n",
        "        print(\"‚ö†Ô∏è Archivo no encontrado. Intenta de nuevo.\")\n",
        "\n",
        "# =================== 4. Procesamiento de audio ===================\n",
        "\n",
        "def process_audio_file(audio_path: str, sex: int) -> pd.DataFrame:\n",
        "    \"\"\"Procesa archivo de audio y extrae features.\"\"\"\n",
        "    print(f\"üîä Cargando audio: {audio_path}\")\n",
        "\n",
        "    # Cargar audio con librosa\n",
        "    try:\n",
        "        audio, sr = librosa.load(audio_path, sr=16_000)\n",
        "        print(f\"üìä Audio cargado: {len(audio)} samples a {sr} Hz ({len(audio)/sr:.2f} segundos)\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"‚ùå Error cargando audio: {e}\")\n",
        "\n",
        "    # Preprocessing\n",
        "    audio = normalize_audio(audio)\n",
        "    audio = remove_silence(audio, sr)\n",
        "\n",
        "    if len(audio) < sr * 1.5:  # Menos de 1.5 segundos\n",
        "        raise RuntimeError(\"‚ö†Ô∏è Audio muy corto despu√©s de quitar silencios\")\n",
        "\n",
        "    print(f\"üîß Audio procesado: {len(audio)/sr:.2f} segundos despu√©s de quitar silencios\")\n",
        "\n",
        "    # Segmentaci√≥n\n",
        "    segments = segment_audio(audio, sr)\n",
        "    if not segments:\n",
        "        raise RuntimeError(\"No se pudieron crear segmentos de audio\")\n",
        "\n",
        "    print(f\"üìä Creados {len(segments)} segmentos para an√°lisis\")\n",
        "\n",
        "    # Extracci√≥n de features\n",
        "    features = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        feat = extract_features(segment, sr)\n",
        "        features.append(feat)\n",
        "        if i < 3:  # Mostrar solo los primeros 3\n",
        "            print(f\"  Segmento {i+1}: MFCC promedio = {feat[:5].round(3)}\")\n",
        "\n",
        "    # Crear DataFrame\n",
        "    df = pd.DataFrame(features, columns=[f\"mfcc_{i}\" for i in range(128)] + [\"zcr\"])\n",
        "    df.insert(0, \"sex\", sex)\n",
        "    df.insert(0, \"filename\", os.path.basename(audio_path))\n",
        "\n",
        "    return df\n",
        "\n",
        "def majority_vote(model, df_features: pd.DataFrame) -> tuple[str, Counter]:\n",
        "    \"\"\"Voto mayoritario sobre segmentos.\"\"\"\n",
        "    try:\n",
        "        X = df_features[model.feature_names_in_]\n",
        "    except AttributeError:\n",
        "        X = df_features.drop(columns=[\"filename\", \"sex\"], errors=\"ignore\")\n",
        "\n",
        "    preds = model.predict(X)\n",
        "    tally = Counter(preds)\n",
        "    return tally.most_common(1)[0][0], tally\n",
        "\n",
        "# ====================== 5. CLI / argumentos =================================\n",
        "\n",
        "def parse_args():\n",
        "    ap = argparse.ArgumentParser(description=\"Inferencia sobre audio WAV\")\n",
        "    ap.add_argument(\"--file\", help=\"Ruta del archivo de audio\")\n",
        "    ap.add_argument(\"--sex\", choices=[\"0\", \"1\"], help=\"0 = male/otro, 1 = female\")\n",
        "    ap.add_argument(\"--model\", default=\"svm_model.pkl\", help=\"Archivo del modelo SVM\")\n",
        "    args, _ = ap.parse_known_args()\n",
        "    return args\n",
        "\n",
        "# ========================== 6. Main =========================================\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    print(\"ü§ñ Cargando modelo SVM...\")\n",
        "    model = load_model(args.model)\n",
        "    print(\"‚úÖ Modelo cargado correctamente\")\n",
        "\n",
        "    # ---------- Obtener sexo ----------\n",
        "    if args.sex is None:\n",
        "        print(\"\\nüë§ Informaci√≥n del paciente:\")\n",
        "        while True:\n",
        "            sex_input = input(\"Sexo (0 = masculino/otro, 1 = femenino): \").strip()\n",
        "            if sex_input in (\"0\", \"1\"):\n",
        "                args.sex = sex_input\n",
        "                break\n",
        "            print(\"‚ö†Ô∏è Por favor ingresa 0 √≥ 1\")\n",
        "\n",
        "    sex = int(args.sex)\n",
        "\n",
        "    # ---------- Obtener archivo de audio ----------\n",
        "    if args.file:\n",
        "        # Archivo especificado por par√°metro\n",
        "        if not os.path.isfile(args.file):\n",
        "            sys.exit(f\"‚ö†Ô∏è Archivo no encontrado: {args.file}\")\n",
        "        audio_path = args.file\n",
        "    else:\n",
        "        # Obtener archivo seg√∫n el entorno\n",
        "        if COLAB:\n",
        "            audio_path = upload_audio_colab()\n",
        "        else:\n",
        "            audio_path = get_audio_file_local()\n",
        "\n",
        "    # ---------- Procesar audio ----------\n",
        "    print(f\"\\nüîÑ Procesando archivo: {audio_path}\")\n",
        "    df = process_audio_file(audio_path, sex)\n",
        "\n",
        "    # ---------- Predicci√≥n ----------\n",
        "    print(\"\\nüß† Ejecutando predicci√≥n...\")\n",
        "    final_label, counts = majority_vote(model, df)\n",
        "\n",
        "    # ---------- Resultado ----------\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"üìÅ Archivo: {os.path.basename(audio_path)}\")\n",
        "    print(f\"üìä Predicciones por segmento: {dict(counts)}\")\n",
        "    print(f\"üéØ RESULTADO FINAL: {final_label}\")\n",
        "    if final_label == 0:\n",
        "      print(f\"üéØ RESULTADO FINAL: {final_label} ‚Äì NO TIENES COVID!\")\n",
        "    else:\n",
        "        print(f\"üéØ RESULTADO FINAL: {final_label} ‚Äì SI TIENES COVID U.U\")\n",
        "    print(f\"üìà Confianza: {counts[final_label]}/{sum(counts.values())} segmentos\")\n",
        "\n",
        "    # Mostrar porcentaje de confianza\n",
        "    confidence_pct = (counts[final_label] / sum(counts.values())) * 100\n",
        "    print(f\"üíØ Porcentaje de segmentos: {confidence_pct:.1f}%\")\n",
        "\n",
        "    # Mostrar detalles por segmento si hay pocos\n",
        "    if len(counts) <= 5:\n",
        "        print(\"\\nüìã Detalle por segmento:\")\n",
        "        for label, count in counts.most_common():\n",
        "            pct = (count / sum(counts.values())) * 100\n",
        "            print(f\"  {label}: {count} segmentos ({pct:.1f}%)\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n‚ùå Cancelado por el usuario\")\n",
        "        sys.exit(0)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nüí• Error: {e}\")\n",
        "        sys.exit(1)"
      ],
      "metadata": {
        "id": "BHsGVRiw12eZ",
        "outputId": "095adaab-5ba0-43b0-af57-714fb103dd9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Cargando modelo SVM...\n",
            "‚úÖ Modelo cargado correctamente\n",
            "\n",
            "üë§ Informaci√≥n del paciente:\n",
            "Sexo (0 = masculino/otro, 1 = femenino): 0\n",
            "üìÅ Por favor, selecciona un archivo de audio WAV...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12f3d219-8d49-4e36-8ebf-4db9022e6f03\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12f3d219-8d49-4e36-8ebf-4db9022e6f03\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 179_Positive_male_25.wav to 179_Positive_male_25.wav\n",
            "\n",
            "üîÑ Procesando archivo: 179_Positive_male_25.wav\n",
            "üîä Cargando audio: 179_Positive_male_25.wav\n",
            "üìä Audio cargado: 98304 samples a 16000 Hz (6.14 segundos)\n",
            "üîß Audio procesado: 5.86 segundos despu√©s de quitar silencios\n",
            "üìä Creados 6 segmentos para an√°lisis\n",
            "  Segmento 1: MFCC promedio = [-459.693   89.929  -13.312   10.389   -9.594]\n",
            "  Segmento 2: MFCC promedio = [-483.239   91.918   -5.656    5.673   -8.652]\n",
            "  Segmento 3: MFCC promedio = [-527.178   99.269  -11.375   -2.381   -9.091]\n",
            "\n",
            "üß† Ejecutando predicci√≥n...\n",
            "\n",
            "============================================================\n",
            "üìÅ Archivo: 179_Positive_male_25.wav\n",
            "üìä Predicciones por segmento: {np.int64(1): 6}\n",
            "üéØ RESULTADO FINAL: 1\n",
            "üéØ RESULTADO FINAL: 1 ‚Äì SI TIENES COVID U.U\n",
            "üìà Confianza: 6/6 segmentos\n",
            "üíØ Porcentaje de segmentos: 100.0%\n",
            "\n",
            "üìã Detalle por segmento:\n",
            "  1: 6 segmentos (100.0%)\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}